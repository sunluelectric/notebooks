\chapter{Applications}

Two examples are given in this section for partial differential and multiple integral applications respectively.

Section \ref{ch8sec:nnbackpropagation} introduces back-propagation for a conventional multi-layer perceptrons artificial neural network. Back-propagation is a key procedure where the neural network ``learns'' from labeled training samples for pattern recognition.

Section \ref{ch8sec:bayesianinference} introduces Bayesian inference, a widely used method for updating the probability of a hypothesis using Bayes theorem.

\section{Neural Network Back-propagation} \label{ch8sec:nnbackpropagation}

The back-propagation of a conventional multi-layer artificial neural network (ANN) is used as an example to illustrate the use of partial differential. 

For the convenience of the reader, preliminary knowledge of the ANN, such as the concept of a perceptron, is introduced in \ref{ch8subsec:perceptron}. The multi-layer perceptrons model used in the example is introduced in \ref{ch8subsec:multilayerperceptrons}. Finally the ANN is trained and tested using the training and testing sets, and the results are given in \ref{ch9subsec:trainingandtesting}.

\subsection{Perceptron} \label{ch8subsec:perceptron}

\subsection{A Multi-layer Perceptrons Model} \label{ch8subsec:multilayerperceptrons}

\subsection{Training and Testing} \label{ch9subsec:trainingandtesting}


\section{Bayesian Inference} \label{ch8sec:bayesianinference}
